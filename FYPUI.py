import gradio as gr
import cv2
import numpy as np
from ultralytics import YOLO
from PIL import Image, ImageDraw, ImageFont # for drawing bounding boxes and labels on the image.

# Load our trained YOLOv10_CBAM model
model = YOLO("D:\downloads\FYPcode\Trained_model\YOLOv10CM_FYPtrained.pt")  # update the path of the trained model

# Store brain tumor classes into class_name
class_names = ["Glioma", "Meningioma", "No Tumor", "Pituitary"]

    # This function receives an image as a NumPy array in RGB format from Gradio,
    # then convert it to BGR. Next, it runs YOLO inference and draws the detection
    # results which are bounding boxes and labels on the image.

def BrainTumorDetection(input_image):

    # Convert the image from RGB (Gradio default) to BGR (OpenCV default)
    image_bgr = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)

    # Run inference on the image by setting confidence threshold at 50%
    results = model.predict(source=image_bgr, conf=0.5)

    # Prepare a list for detections; each detection is (box, label, confidence)
    detections = []

    """
            Author: OpenAI.
            Date: 16 April.
            The section related to extracting and formatting YOLO detection outputs was generated by ChatGPT, including:
            - Bounding box extraction
            - Class label mapping
            - Detection storage structure
            Source: GPT-4o
            URL: https://chatgpt.com/
    """

    if results and len(results):
        # We are processing only one image at a time
        result = results[0]

        if result.boxes is not None:
            # Get bounding box coordinates, class indices, and confidence scores

            boxes = result.boxes.xyxy.cpu().numpy()  # Coordinates: [x1, y1, x2, y2]
            class_ids = result.boxes.cls.cpu().numpy()  # Class indices: (e.g. 0=Glioma, 1=Meningioma, 2=No Tumor, 3=Pituitary)
            confs = result.boxes.conf.cpu().numpy()  # Confidence scores

            # Loop through a combination of 3 array
            for box, class_idz, conf in zip(boxes, class_ids, confs):
                label = class_names[int(class_idz)]     # Map class index into class name
                detections.append((box, label, conf))   # Store detected object info in detections list


    # Convert the original image to a PIL Image for drawing
    output_image = Image.fromarray(input_image)
    draw = ImageDraw.Draw(output_image)
    font = ImageFont.load_default()

    """
            Author: OpenAI.
            Date: 16 April.      
            The section related to drawing bounding boxes and displaying class labels with confidence scores
            was generated using ChatGPT. 
            Source: GPT-4o
            URL: https://chatgpt.com/
    """

    # Draw each detection as a rectangle with a label
    for (box, label, conf) in detections:
        x1, y1, x2, y2 = box.astype(int)
        draw.rectangle([x1, y1, x2, y2], outline="white", width=2)
        draw.text((x1, max(0, y1 - 10)), f"{label} {conf:.2f}", fill="white", font=font)

    # Return the output image as a NumPy array
    return np.array(output_image)


# Define the Gradio interface
iface = gr.Interface(
    fn=BrainTumorDetection,
    inputs=gr.Image(type="numpy"),
    outputs=gr.Image(type="numpy"),
    title="Brain Tumor Detection",
    description="Upload an MRI image to detect brain tumors."
)

if __name__ == "__main__":
    iface.launch()





